{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **FLUX UPSCALER FOR IMAGES & VIDEOS (Local - RTX 5060 Ti)**\n",
    "\n",
    "Adapted from the original Colab notebook for local Windows execution with RTX 5060 Ti.\n",
    "\n",
    "## Setup Instructions\n",
    "1. Run the **Setup Environment** cell first (only needed once)\n",
    "2. Set your `INPUT_IMAGE_PATH` in the **Configuration** cell\n",
    "3. Adjust upscale settings as needed\n",
    "4. Run the **Upscale** cell\n",
    "\n",
    "## Notes\n",
    "- Models are downloaded to `./hf/` directory (relative to this repo)\n",
    "- Output is saved to the repo root directory\n",
    "- For 8GB VRAM variant, reduce `tile_width` and `tile_height` to 384 or 256\n",
    "- The 16GB variant should handle default settings fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\Armaan\\Desktop\\Artinafti\n",
      "Models directory: C:\\Users\\Armaan\\Desktop\\Artinafti\\hf\\models\n",
      "Output directory: C:\\Users\\Armaan\\Desktop\\Artinafti\\4xoutput\n",
      "Installing pip packages...\n",
      "Installing PyTorch nightly with CUDA 12.8 (for RTX 50-series)...\n",
      "✓ PyTorch nightly with CUDA 12.8 installed\n",
      "✓ torchsde installed\n",
      "✓ av installed\n",
      "✓ diffusers installed\n",
      "✓ accelerate installed\n",
      "✓ einops installed\n",
      "✓ spandrel installed\n",
      "✓ opencv-python installed\n",
      "✓ imageio installed\n",
      "✓ imageio-ffmpeg installed\n",
      "✓ huggingface_hub installed\n",
      "✓ safetensors installed\n",
      "✓ gguf installed\n",
      "✓ sentencepiece installed\n",
      "\n",
      "✅ Environment Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "# @title Setup Environment (Run Once)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get repo root (parent of resolution-upscaling folder)\n",
    "NOTEBOOK_DIR = Path(os.getcwd()).resolve()\n",
    "if NOTEBOOK_DIR.name == \"resolution-upscaling\":\n",
    "    REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    REPO_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "# Directory paths\n",
    "HF_DIR = REPO_ROOT / \"hf\"\n",
    "COMFYUI_DIR = HF_DIR / \"ComfyUI\"\n",
    "MODELS_DIR = HF_DIR / \"models\"\n",
    "OUTPUT_DIR = REPO_ROOT / \"4xoutput\"\n",
    "INPUT_DIR = REPO_ROOT / \"input\"\n",
    "\n",
    "# Create directories\n",
    "for d in [HF_DIR, MODELS_DIR, OUTPUT_DIR, INPUT_DIR, \n",
    "          MODELS_DIR / \"upscale_models\", MODELS_DIR / \"unet\", \n",
    "          MODELS_DIR / \"vae\", MODELS_DIR / \"clip\", MODELS_DIR / \"loras\"]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Repo root: {REPO_ROOT}\")\n",
    "print(f\"Models directory: {MODELS_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "def install_pip_packages():\n",
    "    # Install PyTorch NIGHTLY with CUDA 12.8 (required for RTX 5060 Ti sm_120 Blackwell)\n",
    "    print(\"Installing PyTorch nightly with CUDA 12.8 (for RTX 50-series)...\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'install', '-q', '--pre',\n",
    "         'torch', 'torchvision', 'torchaudio',\n",
    "         '--index-url', 'https://download.pytorch.org/whl/nightly/cu128'],\n",
    "        capture_output=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ PyTorch nightly with CUDA 12.8 installed\")\n",
    "    else:\n",
    "        print(f\"✗ PyTorch install failed: {result.stderr.decode()}\")\n",
    "        raise RuntimeError(\"PyTorch CUDA installation failed\")\n",
    "    \n",
    "    # Other packages (xformers removed - optional and causes conflicts)\n",
    "    packages = [\n",
    "        'torchsde',\n",
    "        'av',\n",
    "        'diffusers',\n",
    "        'accelerate',\n",
    "        'einops',\n",
    "        'spandrel',\n",
    "        'opencv-python',\n",
    "        'imageio',\n",
    "        'imageio-ffmpeg',\n",
    "        'huggingface_hub',\n",
    "        'safetensors',\n",
    "        'gguf',\n",
    "        'sentencepiece',\n",
    "    ]\n",
    "\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
    "                check=True,\n",
    "                capture_output=True\n",
    "            )\n",
    "            print(f\"✓ {package} installed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"✗ Error installing {package}: {e.stderr.decode().strip() or 'Unknown error'}\")\n",
    "\n",
    "print(\"Installing pip packages...\")\n",
    "install_pip_packages()\n",
    "\n",
    "# Clone ComfyUI and custom nodes if not present\n",
    "if not COMFYUI_DIR.exists():\n",
    "    print(\"Cloning ComfyUI...\")\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/Isi-dev/ComfyUI', str(COMFYUI_DIR)], check=True)\n",
    "    \n",
    "custom_nodes_dir = COMFYUI_DIR / \"custom_nodes\"\n",
    "custom_nodes_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if not (custom_nodes_dir / \"ComfyUI_GGUF\").exists():\n",
    "    print(\"Cloning ComfyUI_GGUF...\")\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/Isi-dev/ComfyUI_GGUF.git'], cwd=str(custom_nodes_dir), check=True)\n",
    "    # Install GGUF requirements\n",
    "    req_file = custom_nodes_dir / \"ComfyUI_GGUF\" / \"requirements.txt\"\n",
    "    if req_file.exists():\n",
    "        subprocess.run([sys.executable, '-m', 'pip', 'install', '-q', '-r', str(req_file)], check=True)\n",
    "\n",
    "if not (custom_nodes_dir / \"ComfyUI_UltimateSDUpscale\").exists():\n",
    "    print(\"Cloning ComfyUI_UltimateSDUpscale...\")\n",
    "    subprocess.run(['git', 'clone', 'https://github.com/Isi-dev/ComfyUI_UltimateSDUpscale'], cwd=str(custom_nodes_dir), check=True)\n",
    "\n",
    "print(\"\\n✅ Environment Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading upscale models...\n",
      "✓ 4x-UltraSharp.pth already exists\n",
      "✓ 4x_foolhardy_Remacri.pth already exists\n",
      "✓ 4x-AnimeSharp.pth already exists\n",
      "\n",
      "Downloading FLUX model...\n",
      "✓ flux1-dev-Q8_0.gguf already exists\n",
      "\n",
      "Downloading VAE...\n",
      "✓ ae.sft already exists\n",
      "\n",
      "Downloading CLIP models...\n",
      "✓ clip_l.safetensors already exists\n",
      "✓ t5xxl_fp8_e4m3fn.safetensors already exists\n",
      "\n",
      "✅ All models downloaded!\n"
     ]
    }
   ],
   "source": [
    "# @title Download Models (Run Once)\n",
    "import os\n",
    "from pathlib import Path\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "# Get paths from previous cell\n",
    "NOTEBOOK_DIR = Path(os.getcwd()).resolve()\n",
    "if NOTEBOOK_DIR.name == \"resolution-upscaling\":\n",
    "    REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    REPO_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "HF_DIR = REPO_ROOT / \"hf\"\n",
    "MODELS_DIR = HF_DIR / \"models\"\n",
    "\n",
    "# Create model subdirectories\n",
    "UPSCALE_MODELS_DIR = MODELS_DIR / \"upscale_models\"\n",
    "UNET_DIR = MODELS_DIR / \"unet\"\n",
    "VAE_DIR = MODELS_DIR / \"vae\"\n",
    "CLIP_DIR = MODELS_DIR / \"clip\"\n",
    "LORAS_DIR = MODELS_DIR / \"loras\"\n",
    "\n",
    "for d in [UPSCALE_MODELS_DIR, UNET_DIR, VAE_DIR, CLIP_DIR, LORAS_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "download_face_upscalers = False  # Set to True if you want face upscalers\n",
    "download_loRA = False  # Set to True if you want LoRA\n",
    "\n",
    "def download_model(repo_id: str, filename: str, dest_dir: Path, subfolder: str = None) -> str:\n",
    "    \"\"\"Download model from HuggingFace Hub.\"\"\"\n",
    "    dest_path = dest_dir / filename\n",
    "    if dest_path.exists():\n",
    "        print(f\"✓ {filename} already exists\")\n",
    "        return filename\n",
    "    \n",
    "    try:\n",
    "        print(f\"Downloading {filename}...\", end=' ', flush=True)\n",
    "        hf_hub_download(\n",
    "            repo_id=repo_id,\n",
    "            filename=filename if subfolder is None else f\"{subfolder}/{filename}\",\n",
    "            local_dir=str(dest_dir),\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        # Move file if it was downloaded to subfolder\n",
    "        if subfolder:\n",
    "            src = dest_dir / subfolder / filename\n",
    "            if src.exists():\n",
    "                src.rename(dest_path)\n",
    "                (dest_dir / subfolder).rmdir()\n",
    "        print(\"Done!\")\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError downloading {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Downloading upscale models...\")\n",
    "x_UltraSharp = download_model(\"Isi99999/Upscalers\", \"4x-UltraSharp.pth\", UPSCALE_MODELS_DIR)\n",
    "x_foolhardy_Remacri = download_model(\"Isi99999/Upscalers\", \"4x_foolhardy_Remacri.pth\", UPSCALE_MODELS_DIR)\n",
    "x_AnimeSharp = download_model(\"Isi99999/Upscalers\", \"4x-AnimeSharp.pth\", UPSCALE_MODELS_DIR)\n",
    "\n",
    "if download_face_upscalers:\n",
    "    x_FaceUpSharpDAT = download_model(\"Isi99999/Upscalers\", \"4xFaceUpSharpDAT.pth\", UPSCALE_MODELS_DIR)\n",
    "    x_FaceUpSharpLDAT = download_model(\"Isi99999/Upscalers\", \"4xFaceUpSharpLDAT.safetensors\", UPSCALE_MODELS_DIR)\n",
    "\n",
    "print(\"\\nDownloading FLUX model...\")\n",
    "flux_model = download_model(\"city96/FLUX.1-dev-gguf\", \"flux1-dev-Q8_0.gguf\", UNET_DIR)\n",
    "\n",
    "print(\"\\nDownloading VAE...\")\n",
    "flux_vae = download_model(\"Isi99999/Upscalers\", \"ae.sft\", VAE_DIR, subfolder=\"Flux\")\n",
    "\n",
    "print(\"\\nDownloading CLIP models...\")\n",
    "flux_clip_l = download_model(\"Isi99999/Upscalers\", \"clip_l.safetensors\", CLIP_DIR, subfolder=\"Flux\")\n",
    "flux_t5xxl = download_model(\"Isi99999/Upscalers\", \"t5xxl_fp8_e4m3fn.safetensors\", CLIP_DIR, subfolder=\"Flux\")\n",
    "\n",
    "if download_loRA:\n",
    "    print(\"\\nDownloading LoRA...\")\n",
    "    flux_lora = download_model(\"Isi99999/Upscalers\", \"flux_realism_lora.safetensors\", LORAS_DIR, subfolder=\"Flux\")\n",
    "\n",
    "print(\"\\n✅ All models downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries loaded!\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "VRAM: 15.9 GB\n"
     ]
    }
   ],
   "source": [
    "# @title Load Libraries and Initialize\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import imageio\n",
    "import cv2\n",
    "import shutil\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from IPython.display import display, HTML, Image as IPImage\n",
    "\n",
    "# Set up paths\n",
    "NOTEBOOK_DIR = Path(os.getcwd()).resolve()\n",
    "if NOTEBOOK_DIR.name == \"resolution-upscaling\":\n",
    "    REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    REPO_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "HF_DIR = REPO_ROOT / \"hf\"\n",
    "COMFYUI_DIR = HF_DIR / \"ComfyUI\"\n",
    "MODELS_DIR = HF_DIR / \"models\"\n",
    "OUTPUT_DIR = REPO_ROOT / \"4xoutput\"\n",
    "INPUT_DIR = REPO_ROOT / \"input\"\n",
    "\n",
    "# Model paths\n",
    "UPSCALE_MODELS_DIR = MODELS_DIR / \"upscale_models\"\n",
    "UNET_DIR = MODELS_DIR / \"unet\"\n",
    "VAE_DIR = MODELS_DIR / \"vae\"\n",
    "CLIP_DIR = MODELS_DIR / \"clip\"\n",
    "LORAS_DIR = MODELS_DIR / \"loras\"\n",
    "\n",
    "# Add ComfyUI to path\n",
    "sys.path.insert(0, str(COMFYUI_DIR))\n",
    "\n",
    "# Configure ComfyUI folder_paths to use our custom model directories\n",
    "import folder_paths\n",
    "folder_paths.folder_names_and_paths[\"text_encoders\"] = ([str(CLIP_DIR)], folder_paths.supported_pt_extensions)\n",
    "folder_paths.folder_names_and_paths[\"clip\"] = ([str(CLIP_DIR)], folder_paths.supported_pt_extensions)\n",
    "folder_paths.folder_names_and_paths[\"vae\"] = ([str(VAE_DIR)], folder_paths.supported_pt_extensions)\n",
    "folder_paths.folder_names_and_paths[\"diffusion_models\"] = ([str(UNET_DIR)], folder_paths.supported_pt_extensions)\n",
    "folder_paths.folder_names_and_paths[\"unet\"] = ([str(UNET_DIR)], folder_paths.supported_pt_extensions)\n",
    "folder_paths.folder_names_and_paths[\"upscale_models\"] = ([str(UPSCALE_MODELS_DIR)], folder_paths.supported_pt_extensions)\n",
    "folder_paths.folder_names_and_paths[\"loras\"] = ([str(LORAS_DIR)], folder_paths.supported_pt_extensions)\n",
    "\n",
    "# Import ComfyUI modules\n",
    "from nodes import (\n",
    "    DualCLIPLoader,\n",
    "    UNETLoader,\n",
    "    VAELoader,\n",
    "    LoraLoaderModelOnly,\n",
    "    LoadImage,\n",
    "    SaveImage\n",
    ")\n",
    "\n",
    "from custom_nodes.ComfyUI_GGUF.nodes import UnetLoaderGGUF\n",
    "from comfy_extras.nodes_upscale_model import UpscaleModelLoader\n",
    "from comfy_extras.nodes_flux import CLIPTextEncodeFlux\n",
    "from custom_nodes.ComfyUI_UltimateSDUpscale.nodes import (\n",
    "    UltimateSDUpscale,\n",
    "    UltimateSDUpscaleNoUpscale\n",
    ")\n",
    "\n",
    "# Model filenames\n",
    "flux_model = \"flux1-dev-Q8_0.gguf\"\n",
    "flux_vae = \"ae.sft\"\n",
    "flux_clip_l = \"clip_l.safetensors\"\n",
    "flux_t5xxl = \"t5xxl_fp8_e4m3fn.safetensors\"\n",
    "lora = None  # Set if using LoRA\n",
    "\n",
    "# Initialize loaders\n",
    "clip_loader = DualCLIPLoader()\n",
    "unet_loader = UnetLoaderGGUF()\n",
    "vae_loader = VAELoader()\n",
    "load_lora = LoraLoaderModelOnly()\n",
    "load_image = LoadImage()\n",
    "save_image = SaveImage()\n",
    "upscale_model_loader = UpscaleModelLoader()\n",
    "positive_prompt_encode = CLIPTextEncodeFlux()\n",
    "negative_prompt_encode = CLIPTextEncodeFlux()\n",
    "upscaler = UltimateSDUpscale()\n",
    "noUpscale = UltimateSDUpscaleNoUpscale()\n",
    "\n",
    "# Helper functions\n",
    "def clear_memory():\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "\n",
    "def save_as_image(image, filename_prefix, output_dir=None, formats=None):\n",
    "    \"\"\"Save single frame as PNG and/or TIFF image.\n",
    "\n",
    "    Args:\n",
    "        image: Image tensor to save\n",
    "        filename_prefix: Base filename without extension\n",
    "        output_dir: Output directory (defaults to OUTPUT_DIR)\n",
    "        formats: List of formats to save, e.g. [\"png\", \"tiff\"] (defaults to [\"png\", \"tiff\"])\n",
    "\n",
    "    Returns:\n",
    "        List of saved file paths\n",
    "    \"\"\"\n",
    "    if formats is None:\n",
    "        formats = [\"png\", \"tiff\"]\n",
    "    if output_dir is None:\n",
    "        output_dir = OUTPUT_DIR\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    frame = (image.cpu().numpy() * 255).astype(np.uint8)\n",
    "    pil_img = Image.fromarray(frame)\n",
    "\n",
    "    saved_paths = []\n",
    "    for fmt in formats:\n",
    "        fmt_lower = fmt.lower()\n",
    "        if fmt_lower == \"png\":\n",
    "            output_path = output_dir / f\"{filename_prefix}.png\"\n",
    "            pil_img.save(str(output_path), \"PNG\")\n",
    "            saved_paths.append(str(output_path))\n",
    "            print(f\"   Saved: {output_path.name}\")\n",
    "        elif fmt_lower in [\"tiff\", \"tif\"]:\n",
    "            output_path = output_dir / f\"{filename_prefix}.tiff\"\n",
    "            pil_img.save(str(output_path), \"TIFF\", compression=None)\n",
    "            saved_paths.append(str(output_path))\n",
    "            print(f\"   Saved: {output_path.name}\")\n",
    "\n",
    "    return saved_paths\n",
    "\n",
    "def save_as_mp4(images, filename_prefix, fps, output_dir=None):\n",
    "    \"\"\"Save frames as MP4 video.\"\"\"\n",
    "    if output_dir is None:\n",
    "        output_dir = OUTPUT_DIR\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_path = output_dir / f\"{filename_prefix}.mp4\"\n",
    "\n",
    "    frames = []\n",
    "    for i, img in enumerate(images):\n",
    "        try:\n",
    "            if isinstance(img, torch.Tensor):\n",
    "                img = img.cpu().numpy()\n",
    "\n",
    "            if img.max() <= 1.0:\n",
    "                img = (img * 255).astype(np.uint8)\n",
    "            else:\n",
    "                img = img.astype(np.uint8)\n",
    "\n",
    "            if len(img.shape) == 4:\n",
    "                img = img[0]\n",
    "\n",
    "            if len(img.shape) == 3:\n",
    "                if img.shape[0] in (1, 3, 4):\n",
    "                    img = np.transpose(img, (1, 2, 0))\n",
    "                elif img.shape[2] > 4:\n",
    "                    img = img[:, :, :3]\n",
    "            elif len(img.shape) == 2:\n",
    "                img = np.expand_dims(img, axis=-1)\n",
    "\n",
    "            if len(img.shape) != 3 or img.shape[2] not in (1, 3, 4):\n",
    "                raise ValueError(f\"Invalid frame shape after processing: {img.shape}\")\n",
    "\n",
    "            frames.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing frame {i}: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    with imageio.get_writer(str(output_path), fps=fps) as writer:\n",
    "        for frame in frames:\n",
    "            writer.append_data(frame)\n",
    "\n",
    "    return str(output_path)\n",
    "\n",
    "def extract_frames(video_path, max_frames=None):\n",
    "    \"\"\"Extract frames from video and return as a list of images.\"\"\"\n",
    "    vidcap = cv2.VideoCapture(str(video_path))\n",
    "    fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "    frames = []\n",
    "\n",
    "    while True:\n",
    "        success, frame = vidcap.read()\n",
    "        if not success or (max_frames and len(frames) >= max_frames):\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frames.append(frame)\n",
    "\n",
    "    vidcap.release()\n",
    "    if not frames:\n",
    "        return None, fps\n",
    "\n",
    "    print(f\"Extracted {len(frames)} frames\")\n",
    "    return frames, fps\n",
    "\n",
    "def select_every_n_frame(frames, fps, n, skip_first=0, max_output_frames=0):\n",
    "    \"\"\"Select every nth frame from video.\"\"\"\n",
    "    if not frames or n < 1:\n",
    "        raise ValueError(\"Frames must be a non-empty list and n must be >= 1\")\n",
    "\n",
    "    frames_to_use = frames[skip_first:]\n",
    "    if not frames_to_use:\n",
    "        print(\"No frames available after skipping.\")\n",
    "        return [], 0.0\n",
    "\n",
    "    selected_frames = frames_to_use[::n]\n",
    "    if max_output_frames != 0 and len(selected_frames) > max_output_frames:\n",
    "        selected_frames = selected_frames[:max_output_frames]\n",
    "\n",
    "    adjusted_fps = fps / n\n",
    "    print(f\"Adjusted FPS: {adjusted_fps:.2f} -> Final output: {len(selected_frames)} frames\")\n",
    "\n",
    "    return selected_frames, adjusted_fps\n",
    "\n",
    "def display_video(video_path):\n",
    "    \"\"\"Display video in notebook.\"\"\"\n",
    "    from base64 import b64encode\n",
    "\n",
    "    video_data = open(video_path, 'rb').read()\n",
    "    if video_path.lower().endswith('.mp4'):\n",
    "        mime_type = \"video/mp4\"\n",
    "    elif video_path.lower().endswith('.webm'):\n",
    "        mime_type = \"video/webm\"\n",
    "    else:\n",
    "        mime_type = \"video/mp4\"\n",
    "\n",
    "    data_url = f\"data:{mime_type};base64,\" + b64encode(video_data).decode()\n",
    "    display(HTML(f\"\"\"\n",
    "    <video width=512 controls autoplay loop>\n",
    "        <source src=\"{data_url}\" type=\"{mime_type}\">\n",
    "    </video>\n",
    "    \"\"\"))\n",
    "\n",
    "def remove_frame(image_path: str, threshold: float = 0.15, min_frame_width: int = 10, max_frame_width: int = 200) -> str:\n",
    "    \"\"\"\n",
    "    Remove frame/border from an image by detecting and cropping out the frame.\n",
    "    \n",
    "    Uses edge detection and variance analysis to find where the frame ends and content begins.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        threshold: Edge detection threshold (0.0-1.0), lower = more sensitive\n",
    "        min_frame_width: Minimum expected frame width in pixels\n",
    "        max_frame_width: Maximum expected frame width in pixels\n",
    "    \n",
    "    Returns:\n",
    "        Path to the cropped image (saves to same location with '_no_frame' suffix)\n",
    "    \"\"\"\n",
    "    image_path = Path(image_path)\n",
    "    if not image_path.exists():\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "    \n",
    "    # Load image\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    \n",
    "    original_height, original_width = img.shape[:2]\n",
    "    \n",
    "    # Convert to grayscale for analysis\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    def find_frame_edge(scan_range: int, is_horizontal: bool, from_start: bool) -> int:\n",
    "        \"\"\"\n",
    "        Find frame edge by scanning from edge inward.\n",
    "        \n",
    "        Args:\n",
    "            scan_range: How many pixels to scan from the edge\n",
    "            is_horizontal: True for top/bottom edges, False for left/right\n",
    "            from_start: True for top/left, False for bottom/right\n",
    "        \n",
    "        Returns:\n",
    "            Pixel position where content starts (frame ends)\n",
    "        \"\"\"\n",
    "        strip_width = 10\n",
    "        max_variance_pos = 0\n",
    "        max_variance = 0\n",
    "        \n",
    "        if is_horizontal:\n",
    "            if from_start:\n",
    "                # Scan from top\n",
    "                for y in range(0, min(scan_range, original_height - strip_width), 2):\n",
    "                    strip = gray[y:y+strip_width, :]\n",
    "                    variance = np.var(strip)\n",
    "                    if variance > max_variance:\n",
    "                        max_variance = variance\n",
    "                        max_variance_pos = y\n",
    "            else:\n",
    "                # Scan from bottom\n",
    "                for y in range(original_height - min(scan_range, original_height), original_height - strip_width, -2):\n",
    "                    strip = gray[y:y+strip_width, :]\n",
    "                    variance = np.var(strip)\n",
    "                    if variance > max_variance:\n",
    "                        max_variance = variance\n",
    "                        max_variance_pos = y\n",
    "        else:\n",
    "            if from_start:\n",
    "                # Scan from left\n",
    "                for x in range(0, min(scan_range, original_width - strip_width), 2):\n",
    "                    strip = gray[:, x:x+strip_width]\n",
    "                    variance = np.var(strip)\n",
    "                    if variance > max_variance:\n",
    "                        max_variance = variance\n",
    "                        max_variance_pos = x\n",
    "            else:\n",
    "                # Scan from right\n",
    "                for x in range(original_width - min(scan_range, original_width), original_width - strip_width, -2):\n",
    "                    strip = gray[:, x:x+strip_width]\n",
    "                    variance = np.var(strip)\n",
    "                    if variance > max_variance:\n",
    "                        max_variance = variance\n",
    "                        max_variance_pos = x\n",
    "        \n",
    "        return max_variance_pos\n",
    "    \n",
    "    # Find frame edges\n",
    "    scan_range = min(max_frame_width, original_width // 3, original_height // 3)\n",
    "    \n",
    "    top = find_frame_edge(scan_range, True, True)\n",
    "    bottom = find_frame_edge(scan_range, True, False)\n",
    "    left = find_frame_edge(scan_range, False, True)\n",
    "    right = find_frame_edge(scan_range, False, False)\n",
    "    \n",
    "    # Ensure minimum frame width\n",
    "    if top < min_frame_width:\n",
    "        top = min_frame_width\n",
    "    if left < min_frame_width:\n",
    "        left = min_frame_width\n",
    "    if original_height - bottom < min_frame_width:\n",
    "        bottom = original_height - min_frame_width\n",
    "    if original_width - right < min_frame_width:\n",
    "        right = original_width - min_frame_width\n",
    "    \n",
    "    # Ensure valid bounds\n",
    "    top = max(0, min(top, original_height - 20))\n",
    "    bottom = max(top + 20, min(bottom, original_height))\n",
    "    left = max(0, min(left, original_width - 20))\n",
    "    right = max(left + 20, min(right, original_width))\n",
    "    \n",
    "    # Validate crop size (must be at least 50% of original)\n",
    "    content_width = right - left\n",
    "    content_height = bottom - top\n",
    "    \n",
    "    if content_width < original_width * 0.5 or content_height < original_height * 0.5:\n",
    "        # Fallback: conservative crop (remove 3% from each side)\n",
    "        margin = min(original_width, original_height) // 30\n",
    "        top = margin\n",
    "        bottom = original_height - margin\n",
    "        left = margin\n",
    "        right = original_width - margin\n",
    "        print(\"Warning: Frame detection may have failed, using conservative crop\")\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped = img[top:bottom, left:right]\n",
    "    \n",
    "    # Save cropped image\n",
    "    output_path = image_path.parent / f\"{image_path.stem}_no_frame{image_path.suffix}\"\n",
    "    cv2.imwrite(str(output_path), cropped)\n",
    "    \n",
    "    print(f\"Removed frame: cropped from {original_width}x{original_height} to {content_width}x{content_height}\")\n",
    "    print(f\"Removed margins: top={top}, bottom={original_height-bottom}, left={left}, right={original_width-right}\")\n",
    "    \n",
    "    return str(output_path)\n",
    "\n",
    "print(f\"✅ Libraries loaded!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set!\n",
      "Input: C:\\Users\\Armaan\\Desktop\\Artinafti\\9ab756e9-8505-48bd-aa38-3c360d1e29b6.jpg\n",
      "Output dir: C:\\Users\\Armaan\\Desktop\\Artinafti\\6x\n",
      "Mode: Pure 6x upscale (FLUX 4x -> Lanczos to 6x, no downsizing)\n"
     ]
    }
   ],
   "source": [
    "# @title Configuration - 6x Upscale (Single Image, No Downsizing)\n",
    "\n",
    "INPUT_IMAGE = str(REPO_ROOT / \"9ab756e9-8505-48bd-aa38-3c360d1e29b6.jpg\")\n",
    "OUTPUT_DIR = REPO_ROOT / \"6x\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "OUTPUT_FORMATS = [\"png\", \"tiff\"]\n",
    "\n",
    "# ============== PROMPT SETTINGS ==============\n",
    "positive_prompt = \"\"\n",
    "positive_prompt2 = \"\"\n",
    "negative_prompt = \"\"\n",
    "negative_prompt2 = \"\"\n",
    "guidance = 3.5\n",
    "\n",
    "# ============== UPSCALE SETTINGS ==============\n",
    "upscale_by = 4  # Max for FLUX 4x model, will Lanczos resize to 6x after\n",
    "seed = 0\n",
    "steps = 20\n",
    "cfg = 7\n",
    "sampler_name = \"euler\"\n",
    "scheduler = \"normal\"\n",
    "denoise = 0.2\n",
    "\n",
    "upscale_model = \"4x-UltraSharp.pth\"\n",
    "\n",
    "# ============== TILE SETTINGS ==============\n",
    "mode_type = \"Linear\"\n",
    "tile_width = 512\n",
    "tile_height = 512\n",
    "mask_blur = 8\n",
    "tile_padding = 32\n",
    "\n",
    "# ============== SEAM FIX SETTINGS ==============\n",
    "seam_fix_mode = \"None\"\n",
    "seam_fix_denoise = 1.0\n",
    "seam_fix_width = 64\n",
    "seam_fix_mask_blur = 8\n",
    "seam_fix_padding = 16\n",
    "force_uniform_tiles = True\n",
    "tiled_decode = False\n",
    "\n",
    "# ============== LoRA SETTINGS ==============\n",
    "use_loRA = False\n",
    "LoRA_Strength = 1.0\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"Input: {INPUT_IMAGE}\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")\n",
    "print(f\"Mode: Pure 6x upscale (FLUX 4x -> Lanczos to 6x, no downsizing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "6X UPSCALING WITH FLUX\n",
      "============================================================\n",
      "\n",
      "Loading models...\n",
      "Loading Text_Encoder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:clip missing: ['text_projection.weight']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Unet Model...\n",
      "gguf qtypes: F16 (476), Q8_0 (304)\n",
      "Loading upscale model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Armaan\\Desktop\\Artinafti\\hf\\ComfyUI\\custom_nodes\\ComfyUI_GGUF\\loader.py:91: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:219.)\n",
      "  torch_tensor = torch.from_numpy(tensor.data) # mmap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VAE...\n",
      "\n",
      "✅ Models loaded!\n",
      "\n",
      "Input size: 678x1024\n",
      "Target 6x size: 4068x6144\n",
      "Using seed: 2010926999\n",
      "\n",
      "Upscaling 4x with FLUX...\n",
      "Canva size: 2712x4096\n",
      "Image size: 678x1024\n",
      "Tile size: 512x512\n",
      "Tiles amount: 48\n",
      "Grid: 8x6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU:   0%|                                                                                                                                                                                  | 0/4 [00:00<?, ?tile/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e234c1dec0dc4b679998aa70b0af49fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU:  25%|██████████████████████████████████████████▌                                                                                                                               | 1/4 [00:41<02:04, 41.55s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1df44291224a6b86b87d853c1ce0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU:  50%|█████████████████████████████████████████████████████████████████████████████████████                                                                                     | 2/4 [01:10<01:08, 34.06s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9552007cdd6d4f888a5bbc286567add2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                          | 3/4 [01:39<00:31, 31.61s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c21f886cc44f0681bb1c4651d2f6fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [02:07<00:00, 30.46s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6411af3c722421b96f8fa761b8f7a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 5tile [02:36, 29.82s/tile]                                                                                                                                                                                     "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f67dad04353e44ebaf2c31edb0cc78d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 6tile [03:05, 29.43s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc1ff97b85542258639175ba0c941d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 7tile [03:33, 29.20s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6d2a2bda4244e89a0ce182f273d9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 8tile [04:02, 29.03s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4535a56b157547ffaaadc24262139411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 9tile [04:31, 28.92s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5024c9f54d3e4c44b46aba5fbdb1e5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 10tile [04:59, 28.86s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc069adddc8442029010c00463e59ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 11tile [05:28, 28.82s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562aeaa11d1c444fb1031443afb9d4fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 12tile [05:57, 28.79s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9341b62452c4d2eb61ea72451133b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 13tile [06:26, 28.76s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b32e69ca8f246c4a7a559002a4f27d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 14tile [06:54, 28.74s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72589dcb79374e08ba50e667d484cc4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 15tile [07:23, 28.72s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8161ac76c77746c0ad63e908de8ff823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 16tile [07:52, 28.76s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccea488ae9e942419ac124d168311525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 17tile [08:21, 29.03s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c007bda131d41b4ba9e073b7126c542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 18tile [08:51, 29.26s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac6311b9c6e4922bc11abe39bf06aa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 19tile [09:21, 29.40s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e4076a05ed437b84a7e0bbf3b955d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 20tile [09:51, 29.70s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87007e3bff264145b444b88fae9c78fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 21tile [10:20, 29.47s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43a51bbea29240d39a89ce9acb2a2c12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 22tile [10:50, 29.40s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb0895df2d9b45f88f28eb844de8cc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 23tile [11:19, 29.35s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e9c0ffb72e84d12b9f031b17c7a1c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 24tile [11:48, 29.40s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffd0c3aa21c42d9a2dbbd8d8a584834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 25tile [12:18, 29.44s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a1782401b44e3d9aa3acdb879ed9b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 26tile [12:47, 29.46s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e379ad4b81894e4da48d9e612b29e61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 27tile [13:17, 29.47s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93ecd1cc33f46598db493a269d8066c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 28tile [13:46, 29.33s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25c2b7d944a4a89a839620512948720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 29tile [14:15, 29.14s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08dd5dacc8fb40658390290cb50dbe58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 30tile [14:43, 29.01s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bb39fd6b7f64f3a8986b77c3b2cd359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 31tile [15:12, 29.02s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c465c5e6c1764454b998ba28ad6d4728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 32tile [15:42, 29.18s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f849c059a2e74aaabaee3901de509c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 33tile [16:11, 29.32s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e35467f6fb845628d6aa728aeaae15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 34tile [16:41, 29.38s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af19997563b483aa157f05d73dd1476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 35tile [17:10, 29.32s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c43fdf2aa48418e9f3c5a25e797c44e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 36tile [17:39, 29.26s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468660e70dcd4a9190eea5d16d40f88d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 37tile [18:09, 29.30s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5354e661cac54b729e3cdec7fa6584b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 38tile [18:38, 29.25s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e97800808bf416c8efcd74fc5d7f2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 39tile [19:07, 29.21s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc80c9f2ec474a0b8e60bdbe211c8d4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 40tile [19:37, 29.42s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b3d08a3c53540bea68ccd3d6b32ff1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 41tile [20:07, 29.56s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c77bdeaff26647c5ba2a8e0725556351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 42tile [20:36, 29.56s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47ea4ac377441da8f8cebc9adafb036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 43tile [21:05, 29.34s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0702825169046a5b811fecfc9deda83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 44tile [21:35, 29.37s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f934de3488324070b1bd5b5b66f00835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 45tile [22:04, 29.45s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bc5a8d70f04d038717823dbb35b3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 46tile [22:34, 29.66s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa201958b284aed8e80d7710dd55580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 47tile [23:04, 29.76s/tile]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80aa939df2841c688ce0cbe4b5ea5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USDU: 48tile [23:35, 29.48s/tile]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLUX output: 2712x4096 (took 1419.4s)\n",
      "Resizing to 6x (4068x6144) with Lanczos...\n",
      "\n",
      "Saving outputs (png, tiff)...\n",
      "   Saved: 9ab756e9-8505-48bd-aa38-3c360d1e29b6_flux-6x.png\n",
      "   Saved: 9ab756e9-8505-48bd-aa38-3c360d1e29b6_flux-6x.tiff\n",
      "\n",
      "✅ Done! Total time: 1423.1s\n",
      "Output: 4068x6144 (6x upscale, no downsizing)\n"
     ]
    }
   ],
   "source": [
    "# @title Run 6x Upscaling with FLUX\n",
    "\n",
    "import time as _time\n",
    "import random\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"6X UPSCALING WITH FLUX\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    # Load models\n",
    "    print(\"\\nLoading models...\")\n",
    "\n",
    "    print(\"Loading Text_Encoder...\")\n",
    "    clip = clip_loader.load_clip(flux_t5xxl, flux_clip_l, \"flux\")[0]\n",
    "    positive = positive_prompt_encode.encode(clip, positive_prompt, positive_prompt2, guidance)[0]\n",
    "    negative = negative_prompt_encode.encode(clip, negative_prompt, negative_prompt2, guidance)[0]\n",
    "    del clip\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Loading Unet Model...\")\n",
    "    model = unet_loader.load_unet(flux_model)[0]\n",
    "\n",
    "    print(\"Loading upscale model...\")\n",
    "    upscale_model_load = upscale_model_loader.load_model(upscale_model)[0]\n",
    "\n",
    "    print(\"Loading VAE...\")\n",
    "    vae = vae_loader.load_vae(flux_vae)[0]\n",
    "\n",
    "    if use_loRA and lora is not None:\n",
    "        print(\"Loading LoRA...\")\n",
    "        model = load_lora.load_lora_model_only(model, lora, LoRA_Strength)[0]\n",
    "\n",
    "    print(\"\\n✅ Models loaded!\\n\")\n",
    "\n",
    "    # Load image\n",
    "    loaded_image = load_image.load_image(INPUT_IMAGE)[0]\n",
    "    input_h, input_w = loaded_image.shape[1], loaded_image.shape[2]\n",
    "    target_w, target_h = input_w * 6, input_h * 6\n",
    "\n",
    "    print(f\"Input size: {input_w}x{input_h}\")\n",
    "    print(f\"Target 6x size: {target_w}x{target_h}\")\n",
    "\n",
    "    actual_seed = seed if seed != 0 else random.randint(0, 2**32 - 1)\n",
    "    print(f\"Using seed: {actual_seed}\")\n",
    "\n",
    "    # FLUX 4x upscale\n",
    "    print(\"\\nUpscaling 4x with FLUX...\")\n",
    "    start_time = _time.time()\n",
    "\n",
    "    image_out = upscaler.upscale(\n",
    "        image=loaded_image,\n",
    "        model=model,\n",
    "        positive=positive,\n",
    "        negative=negative,\n",
    "        vae=vae,\n",
    "        upscale_by=upscale_by,\n",
    "        seed=actual_seed,\n",
    "        steps=steps,\n",
    "        cfg=cfg,\n",
    "        sampler_name=sampler_name,\n",
    "        scheduler=scheduler,\n",
    "        denoise=denoise,\n",
    "        upscale_model=upscale_model_load,\n",
    "        mode_type=mode_type,\n",
    "        tile_width=tile_width,\n",
    "        tile_height=tile_height,\n",
    "        mask_blur=mask_blur,\n",
    "        tile_padding=tile_padding,\n",
    "        seam_fix_mode=seam_fix_mode,\n",
    "        seam_fix_denoise=seam_fix_denoise,\n",
    "        seam_fix_mask_blur=seam_fix_mask_blur,\n",
    "        seam_fix_width=seam_fix_width,\n",
    "        seam_fix_padding=seam_fix_padding,\n",
    "        force_uniform_tiles=force_uniform_tiles,\n",
    "        tiled_decode=tiled_decode,\n",
    "    )[0]\n",
    "\n",
    "    upscale_time = _time.time() - start_time\n",
    "    flux_h, flux_w = image_out.shape[1], image_out.shape[2]\n",
    "    print(f\"FLUX output: {flux_w}x{flux_h} (took {upscale_time:.1f}s)\")\n",
    "\n",
    "    # Lanczos resize from 4x to 6x\n",
    "    print(f\"Resizing to 6x ({target_w}x{target_h}) with Lanczos...\")\n",
    "    img_np = (image_out[0].cpu().numpy() * 255).astype(np.uint8)\n",
    "    pil_img = Image.fromarray(img_np)\n",
    "    pil_img = pil_img.resize((target_w, target_h), Image.LANCZOS)\n",
    "    resized_np = np.array(pil_img).astype(np.float32) / 255.0\n",
    "    resized_tensor = torch.from_numpy(resized_np).unsqueeze(0)\n",
    "\n",
    "    # Save\n",
    "    output_name = \"9ab756e9-8505-48bd-aa38-3c360d1e29b6_flux-6x\"\n",
    "    print(f\"\\nSaving outputs ({', '.join(OUTPUT_FORMATS)})...\")\n",
    "    save_as_image(resized_tensor[0], output_name, output_dir=OUTPUT_DIR, formats=OUTPUT_FORMATS)\n",
    "\n",
    "    # Cleanup\n",
    "    del model, vae, upscale_model_load, positive, negative, image_out\n",
    "    clear_memory()\n",
    "\n",
    "total_time = _time.time() - start_time\n",
    "print(f\"\\n✅ Done! Total time: {total_time:.1f}s\")\n",
    "print(f\"Output: {target_w}x{target_h} (6x upscale, no downsizing)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
