{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Real-ESRGAN Standalone Upscaler (Fast Mode)**\n",
    "\n",
    "A fast upscaling solution using Real-ESRGAN/ESRGAN models directly without diffusion.\n",
    "\n",
    "## Speed Comparison\n",
    "- **This notebook**: ~10-60 seconds per image (4x upscale)\n",
    "- **FLUX notebook**: ~10-20 minutes per image (4x upscale)\n",
    "\n",
    "## When to Use\n",
    "- Fast batch processing\n",
    "- When original image quality is already good\n",
    "- Preview/proof before final FLUX upscale\n",
    "- When you don't need AI-generated detail enhancement\n",
    "\n",
    "## Available Models\n",
    "- `4x-UltraSharp.pth` - Sharp details, good for digital art (default)\n",
    "- `4x_foolhardy_Remacri.pth` - Natural textures, less over-sharpening\n",
    "- `4x-AnimeSharp.pth` - Optimized for anime/illustration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: C:\\Users\\Armaan\\Desktop\\Artinafti\n",
      "Models directory: C:\\Users\\Armaan\\Desktop\\Artinafti\\hf\\models\\upscale_models\n",
      "Output directory: C:\\Users\\Armaan\\Desktop\\Artinafti\\4xoutput\n",
      "Installing packages...\n",
      "Installing PyTorch nightly with CUDA 12.8...\n",
      "✓ PyTorch installed\n",
      "✓ spandrel installed\n",
      "✓ opencv-python installed\n",
      "✓ huggingface_hub installed\n",
      "✓ safetensors installed\n",
      "✓ pillow installed\n",
      "\n",
      "✅ Environment Setup Complete!\n"
     ]
    }
   ],
   "source": [
    "# @title Setup Environment (Run Once)\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Get repo root\n",
    "NOTEBOOK_DIR = Path(os.getcwd()).resolve()\n",
    "if NOTEBOOK_DIR.name == \"resolution-upscaling\":\n",
    "    REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    REPO_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "# Directory paths\n",
    "HF_DIR = REPO_ROOT / \"hf\"\n",
    "MODELS_DIR = HF_DIR / \"models\"\n",
    "UPSCALE_MODELS_DIR = MODELS_DIR / \"upscale_models\"\n",
    "OUTPUT_DIR = REPO_ROOT / \"4xoutput\"\n",
    "INPUT_DIR = REPO_ROOT / \"input\"\n",
    "\n",
    "# Create directories\n",
    "for d in [HF_DIR, MODELS_DIR, UPSCALE_MODELS_DIR, OUTPUT_DIR, INPUT_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Repo root: {REPO_ROOT}\")\n",
    "print(f\"Models directory: {UPSCALE_MODELS_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "def install_packages():\n",
    "    \"\"\"Install required packages for Real-ESRGAN standalone.\"\"\"\n",
    "    # PyTorch with CUDA 12.8 for RTX 5060 Ti\n",
    "    print(\"Installing PyTorch nightly with CUDA 12.8...\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'pip', 'install', '-q', '--pre',\n",
    "         'torch', 'torchvision',\n",
    "         '--index-url', 'https://download.pytorch.org/whl/nightly/cu128'],\n",
    "        capture_output=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ PyTorch installed\")\n",
    "    else:\n",
    "        print(f\"✗ PyTorch install failed: {result.stderr.decode()}\")\n",
    "    \n",
    "    # Spandrel for loading upscale models\n",
    "    packages = ['spandrel', 'opencv-python', 'huggingface_hub', 'safetensors', 'pillow']\n",
    "    for package in packages:\n",
    "        try:\n",
    "            subprocess.run(\n",
    "                [sys.executable, '-m', 'pip', 'install', '-q', package],\n",
    "                check=True, capture_output=True\n",
    "            )\n",
    "            print(f\"✓ {package} installed\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"✗ Error installing {package}\")\n",
    "\n",
    "print(\"Installing packages...\")\n",
    "install_packages()\n",
    "print(\"\\n✅ Environment Setup Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading upscale models...\n",
      "✓ 4x-UltraSharp.pth already exists\n",
      "✓ 4x_foolhardy_Remacri.pth already exists\n",
      "✓ 4x-AnimeSharp.pth already exists\n",
      "\n",
      "✅ Models downloaded!\n"
     ]
    }
   ],
   "source": [
    "# @title Download Models (Run Once)\n",
    "from huggingface_hub import hf_hub_download\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Ensure paths are set\n",
    "NOTEBOOK_DIR = Path(os.getcwd()).resolve()\n",
    "if NOTEBOOK_DIR.name == \"resolution-upscaling\":\n",
    "    REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    REPO_ROOT = NOTEBOOK_DIR\n",
    "UPSCALE_MODELS_DIR = REPO_ROOT / \"hf\" / \"models\" / \"upscale_models\"\n",
    "UPSCALE_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def download_model(repo_id: str, filename: str, dest_dir: Path) -> str:\n",
    "    \"\"\"Download model from HuggingFace Hub.\"\"\"\n",
    "    dest_path = dest_dir / filename\n",
    "    if dest_path.exists():\n",
    "        print(f\"✓ {filename} already exists\")\n",
    "        return filename\n",
    "    \n",
    "    try:\n",
    "        print(f\"Downloading {filename}...\", end=' ', flush=True)\n",
    "        hf_hub_download(\n",
    "            repo_id=repo_id,\n",
    "            filename=filename,\n",
    "            local_dir=str(dest_dir),\n",
    "            local_dir_use_symlinks=False\n",
    "        )\n",
    "        print(\"Done!\")\n",
    "        return filename\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError downloading {filename}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Downloading upscale models...\")\n",
    "download_model(\"Isi99999/Upscalers\", \"4x-UltraSharp.pth\", UPSCALE_MODELS_DIR)\n",
    "download_model(\"Isi99999/Upscalers\", \"4x_foolhardy_Remacri.pth\", UPSCALE_MODELS_DIR)\n",
    "download_model(\"Isi99999/Upscalers\", \"4x-AnimeSharp.pth\", UPSCALE_MODELS_DIR)\n",
    "\n",
    "print(\"\\n✅ Models downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries loaded!\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "VRAM: 15.9 GB\n"
     ]
    }
   ],
   "source": [
    "# @title Load Libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Image as IPImage\n",
    "\n",
    "# Import spandrel for model loading\n",
    "from spandrel import ImageModelDescriptor, ModelLoader\n",
    "\n",
    "# Set up paths\n",
    "NOTEBOOK_DIR = Path(os.getcwd()).resolve()\n",
    "if NOTEBOOK_DIR.name == \"resolution-upscaling\":\n",
    "    REPO_ROOT = NOTEBOOK_DIR.parent\n",
    "else:\n",
    "    REPO_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "UPSCALE_MODELS_DIR = REPO_ROOT / \"hf\" / \"models\" / \"upscale_models\"\n",
    "OUTPUT_DIR = REPO_ROOT / \"4xoutput\"\n",
    "INPUT_DIR = REPO_ROOT / \"input\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Device setup\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def clear_memory():\n",
    "    \"\"\"Clear GPU memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    gc.collect()\n",
    "\n",
    "print(f\"✅ Libraries loaded!\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration set!\n",
      "Model: 4x-UltraSharp.pth\n",
      "Tile size: 512\n",
      "DPI: 150\n",
      "\n",
      "Images to process:\n",
      "  b46bc519...: 10x20\" -> 1500x3000px\n"
     ]
    }
   ],
   "source": [
    "# @title Configuration - Batch Processing with Custom Output Sizes\n",
    "\n",
    "# ============== BATCH INPUT WITH CUSTOM OUTPUT SIZES ==============\n",
    "# Each image has its own target print size (width x height in inches)\n",
    "# The upscaler will:\n",
    "#   1. Upscale with Real-ESRGAN (4x)\n",
    "#   2. Resize to exact target dimensions for printing\n",
    "\n",
    "DPI = 150\n",
    "\n",
    "IMAGE_CONFIGS = [\n",
    "    {\n",
    "        \"image_id\": \"b46bc519-9b4b-487f-b8d4-b95195d7e02e\",\n",
    "        \"input_path\": \"input/b46bc519-9b4b-487f-b8d4-b95195d7e02e.jpg\",\n",
    "        \"width_inches\": 10,\n",
    "        \"height_inches\": 20,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Use 6x upscaling (two passes of 4x model, then downscale)\n",
    "USE_6X_UPSCALE = True\n",
    "\n",
    "# Calculate target pixel dimensions\n",
    "for config in IMAGE_CONFIGS:\n",
    "    config[\"target_width\"] = config[\"width_inches\"] * DPI\n",
    "    config[\"target_height\"] = config[\"height_inches\"] * DPI\n",
    "\n",
    "# ============== UPSCALE SETTINGS ==============\n",
    "# Model options: \"4x-UltraSharp.pth\", \"4x_foolhardy_Remacri.pth\", \"4x-AnimeSharp.pth\"\n",
    "upscale_model = \"4x-UltraSharp.pth\"\n",
    "\n",
    "# Tile size for processing (larger = faster but more VRAM)\n",
    "# For 16GB VRAM: 512-768 is safe\n",
    "# For 8GB VRAM: 256-384 recommended\n",
    "tile_size = 512\n",
    "tile_overlap = 32  # Overlap between tiles to reduce seams\n",
    "\n",
    "# Use FP16 for faster processing (recommended for RTX cards)\n",
    "use_fp16 = True\n",
    "\n",
    "print(\"Configuration set!\")\n",
    "print(f\"Model: {upscale_model}\")\n",
    "print(f\"Tile size: {tile_size}\")\n",
    "print(f\"DPI: {DPI}\")\n",
    "print(f\"\\nImages to process:\")\n",
    "for config in IMAGE_CONFIGS:\n",
    "    print(f\"  {config['image_id'][:8]}...: {config['width_inches']}x{config['height_inches']}\\\" -> {config['target_width']}x{config['target_height']}px\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Functions defined!\n"
     ]
    }
   ],
   "source": [
    "# @title Upscale Functions\n",
    "\n",
    "def upscale_with_tiles(model, img_tensor: torch.Tensor, tile_size: int, tile_overlap: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Upscale image using tiled processing to handle large images.\n",
    "    \n",
    "    Args:\n",
    "        model: Loaded spandrel model\n",
    "        img_tensor: Input image tensor (B, C, H, W)\n",
    "        tile_size: Size of each tile\n",
    "        tile_overlap: Overlap between tiles\n",
    "    \n",
    "    Returns:\n",
    "        Upscaled image tensor\n",
    "    \"\"\"\n",
    "    scale = model.scale\n",
    "    _, _, h, w = img_tensor.shape\n",
    "    \n",
    "    # If image is small enough, process directly\n",
    "    if h <= tile_size and w <= tile_size:\n",
    "        with torch.no_grad():\n",
    "            return model(img_tensor)\n",
    "    \n",
    "    # Calculate output size\n",
    "    out_h, out_w = h * scale, w * scale\n",
    "    output = torch.zeros((1, 3, out_h, out_w), device=img_tensor.device, dtype=img_tensor.dtype)\n",
    "    weight = torch.zeros((1, 1, out_h, out_w), device=img_tensor.device, dtype=img_tensor.dtype)\n",
    "    \n",
    "    # Calculate tile positions\n",
    "    stride = tile_size - tile_overlap\n",
    "    h_tiles = max(1, (h - tile_overlap) // stride + (1 if (h - tile_overlap) % stride else 0))\n",
    "    w_tiles = max(1, (w - tile_overlap) // stride + (1 if (w - tile_overlap) % stride else 0))\n",
    "    \n",
    "    total_tiles = h_tiles * w_tiles\n",
    "    print(f\"Processing {total_tiles} tiles ({h_tiles}x{w_tiles})...\")\n",
    "    \n",
    "    tile_count = 0\n",
    "    for i in range(h_tiles):\n",
    "        for j in range(w_tiles):\n",
    "            # Calculate tile boundaries\n",
    "            y1 = min(i * stride, h - tile_size) if h > tile_size else 0\n",
    "            x1 = min(j * stride, w - tile_size) if w > tile_size else 0\n",
    "            y2 = min(y1 + tile_size, h)\n",
    "            x2 = min(x1 + tile_size, w)\n",
    "            \n",
    "            # Extract and process tile\n",
    "            tile = img_tensor[:, :, y1:y2, x1:x2]\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                tile_out = model(tile)\n",
    "            \n",
    "            # Calculate output positions\n",
    "            out_y1, out_y2 = y1 * scale, y2 * scale\n",
    "            out_x1, out_x2 = x1 * scale, x2 * scale\n",
    "            \n",
    "            # Create weight mask for blending\n",
    "            tile_h, tile_w = tile_out.shape[2:]\n",
    "            mask = torch.ones((1, 1, tile_h, tile_w), device=tile_out.device, dtype=tile_out.dtype)\n",
    "            \n",
    "            # Feather edges for blending\n",
    "            feather = tile_overlap * scale // 2\n",
    "            if feather > 0:\n",
    "                # Top edge\n",
    "                if i > 0:\n",
    "                    for k in range(feather):\n",
    "                        mask[:, :, k, :] *= k / feather\n",
    "                # Bottom edge\n",
    "                if i < h_tiles - 1:\n",
    "                    for k in range(feather):\n",
    "                        mask[:, :, -(k+1), :] *= k / feather\n",
    "                # Left edge\n",
    "                if j > 0:\n",
    "                    for k in range(feather):\n",
    "                        mask[:, :, :, k] *= k / feather\n",
    "                # Right edge\n",
    "                if j < w_tiles - 1:\n",
    "                    for k in range(feather):\n",
    "                        mask[:, :, :, -(k+1)] *= k / feather\n",
    "            \n",
    "            # Add to output with blending\n",
    "            output[:, :, out_y1:out_y2, out_x1:out_x2] += tile_out * mask\n",
    "            weight[:, :, out_y1:out_y2, out_x1:out_x2] += mask\n",
    "            \n",
    "            tile_count += 1\n",
    "            print(f\"  Processed {tile_count}/{total_tiles} tiles\", end='\\r')\n",
    "    \n",
    "    print(f\"  Processed {tile_count}/{total_tiles} tiles\")\n",
    "    \n",
    "    # Normalize by weights\n",
    "    output = output / weight.clamp(min=1e-8)\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "def upscale_and_resize(\n",
    "    image_path: str,\n",
    "    target_width: int,\n",
    "    target_height: int,\n",
    "    output_name: str,\n",
    "    model_name: str,\n",
    "    tile_size: int,\n",
    "    tile_overlap: int,\n",
    "    use_fp16: bool,\n",
    "    use_two_pass: bool\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Upscale image with Real-ESRGAN and resize to exact target dimensions.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Path to input image\n",
    "        target_width: Target width in pixels\n",
    "        target_height: Target height in pixels\n",
    "        output_name: Output filename (without extension)\n",
    "        model_name: Name of upscale model\n",
    "        tile_size: Tile size for processing\n",
    "        tile_overlap: Overlap between tiles\n",
    "        use_fp16: Use FP16 precision\n",
    "        use_two_pass: If True, run 4x model twice for 16x total (effective 6x+)\n",
    "    \n",
    "    Returns:\n",
    "        Path to output image\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Resolve image path\n",
    "    image_path = Path(image_path)\n",
    "    if not image_path.is_absolute():\n",
    "        image_path = REPO_ROOT / image_path\n",
    "    \n",
    "    if not image_path.exists():\n",
    "        raise FileNotFoundError(f\"Input file not found: {image_path}\")\n",
    "    \n",
    "    print(f\"Processing: {image_path.name}\")\n",
    "    print(f\"Target output: {target_width}x{target_height}px\")\n",
    "    \n",
    "    # Load image\n",
    "    print(\"Loading image...\")\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Could not load image: {image_path}\")\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    print(f\"Input size: {w}x{h}\")\n",
    "    \n",
    "    # Calculate effective scale\n",
    "    effective_scale = 16 if use_two_pass else 4\n",
    "    upscaled_w, upscaled_h = w * effective_scale, h * effective_scale\n",
    "    \n",
    "    if use_two_pass:\n",
    "        print(f\"Strategy: Two-pass 4x upscale (16x total: {upscaled_w}x{upscaled_h}) then downscale to target\")\n",
    "    else:\n",
    "        if upscaled_w >= target_width and upscaled_h >= target_height:\n",
    "            print(f\"Strategy: Upscale 4x ({upscaled_w}x{upscaled_h}) then downscale to target\")\n",
    "        else:\n",
    "            print(f\"⚠️ Warning: 4x upscale ({upscaled_w}x{upscaled_h}) may not reach target size\")\n",
    "    \n",
    "    # Convert to tensor\n",
    "    img_tensor = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "    img_tensor = img_tensor.to(DEVICE)\n",
    "    \n",
    "    if use_fp16 and DEVICE.type == \"cuda\":\n",
    "        img_tensor = img_tensor.half()\n",
    "    \n",
    "    # Load model\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    model_path = UPSCALE_MODELS_DIR / model_name\n",
    "    if not model_path.exists():\n",
    "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "    \n",
    "    model = ModelLoader().load_from_file(str(model_path))\n",
    "    assert isinstance(model, ImageModelDescriptor), \"Not an image model!\"\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    if use_fp16 and DEVICE.type == \"cuda\":\n",
    "        model = model.half()\n",
    "    model.eval()\n",
    "    \n",
    "    scale = model.scale\n",
    "    print(f\"Model scale: {scale}x\")\n",
    "    \n",
    "    # First pass upscale\n",
    "    print(\"Upscaling (pass 1 of {})...\".format(2 if use_two_pass else 1))\n",
    "    upscale_start = time.time()\n",
    "    \n",
    "    output_tensor = upscale_with_tiles(model, img_tensor, tile_size, tile_overlap)\n",
    "    \n",
    "    pass1_time = time.time() - upscale_start\n",
    "    print(f\"Pass 1 took: {pass1_time:.1f}s\")\n",
    "    \n",
    "    # Second pass if requested\n",
    "    if use_two_pass:\n",
    "        print(\"Upscaling (pass 2 of 2)...\")\n",
    "        pass2_start = time.time()\n",
    "        \n",
    "        # Use smaller tile size for second pass (image is now 4x larger)\n",
    "        tile_size_pass2 = min(tile_size, 384)  # Smaller tiles for larger image\n",
    "        output_tensor = upscale_with_tiles(model, output_tensor, tile_size_pass2, tile_overlap)\n",
    "        \n",
    "        pass2_time = time.time() - pass2_start\n",
    "        print(f\"Pass 2 took: {pass2_time:.1f}s\")\n",
    "    \n",
    "    total_upscale_time = time.time() - upscale_start\n",
    "    print(f\"Total upscaling took: {total_upscale_time:.1f}s\")\n",
    "    \n",
    "    # Convert back to image\n",
    "    output = output_tensor.squeeze(0).permute(1, 2, 0).float().cpu().numpy()\n",
    "    output = (output * 255).clip(0, 255).astype(np.uint8)\n",
    "    \n",
    "    upscaled_h, upscaled_w = output.shape[:2]\n",
    "    print(f\"Upscaled size: {upscaled_w}x{upscaled_h}\")\n",
    "    \n",
    "    # Resize to exact target dimensions using high-quality Lanczos\n",
    "    print(f\"Resizing to target: {target_width}x{target_height}...\")\n",
    "    pil_img = Image.fromarray(output)\n",
    "    pil_img = pil_img.resize((target_width, target_height), Image.LANCZOS)\n",
    "    \n",
    "    # Convert back to numpy for saving with cv2\n",
    "    output = np.array(pil_img)\n",
    "    output = cv2.cvtColor(output, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    # Save output\n",
    "    output_path = OUTPUT_DIR / f\"{output_name}.png\"\n",
    "    cv2.imwrite(str(output_path), output)\n",
    "    \n",
    "    # Cleanup\n",
    "    del model, img_tensor, output_tensor\n",
    "    clear_memory()\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✅ Done!\")\n",
    "    print(f\"Output: {output_path}\")\n",
    "    print(f\"Final size: {target_width}x{target_height}\")\n",
    "    print(f\"Total time: {total_time:.1f}s\")\n",
    "    \n",
    "    return str(output_path)\n",
    "\n",
    "print(\"✅ Functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "BATCH UPSCALING WITH CUSTOM OUTPUT SIZES\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "[1/1] b46bc519-9b4b-487f-b8d4-b95195d7e02e\n",
      "Target: 10x20\" at 150 DPI\n",
      "============================================================\n",
      "Processing: b46bc519-9b4b-487f-b8d4-b95195d7e02e.jpg\n",
      "Target output: 1500x3000px\n",
      "Loading image...\n",
      "Input size: 1024x587\n",
      "Strategy: Two-pass 4x upscale (16x total: 16384x9392) then downscale to target\n",
      "Loading model: 4x-UltraSharp.pth\n",
      "Model scale: 4x\n",
      "Upscaling (pass 1 of 2)...\n",
      "Processing 6 tiles (2x3)...\n",
      "  Processed 6/6 tiles\n",
      "Pass 1 took: 4.1s\n",
      "Upscaling (pass 2 of 2)...\n",
      "Processing 84 tiles (7x12)...\n",
      "  Processed 84/84 tiles\n",
      "Pass 2 took: 28.6s\n",
      "Total upscaling took: 32.7s\n",
      "Upscaled size: 16384x9392\n",
      "Resizing to target: 1500x3000...\n",
      "\n",
      "✅ Done!\n",
      "Output: C:\\Users\\Armaan\\Desktop\\Artinafti\\4xoutput\\b46bc519-9b4b-487f-b8d4-b95195d7e02e_real-esrgan.png\n",
      "Final size: 1500x3000\n",
      "Total time: 37.6s\n",
      "\n",
      "\n",
      "============================================================\n",
      "BATCH COMPLETE - SUMMARY\n",
      "============================================================\n",
      "\n",
      "Processed: 1/1 images successfully\n",
      "\n",
      "✅ b46bc519... -> 10x20\" -> b46bc519-9b4b-487f-b8d4-b95195d7e02e_real-esrgan.png\n"
     ]
    }
   ],
   "source": [
    "# @title Run Batch Upscaling\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"BATCH UPSCALING WITH CUSTOM OUTPUT SIZES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, config in enumerate(IMAGE_CONFIGS, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"[{i}/{len(IMAGE_CONFIGS)}] {config['image_id']}\")\n",
    "    print(f\"Target: {config['width_inches']}x{config['height_inches']}\\\" at {DPI} DPI\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        output_name = f\"{config['image_id']}_real-esrgan\"\n",
    "        \n",
    "        output_path = upscale_and_resize(\n",
    "            image_path=config[\"input_path\"],\n",
    "            target_width=config[\"target_width\"],\n",
    "            target_height=config[\"target_height\"],\n",
    "            output_name=output_name,\n",
    "            model_name=upscale_model,\n",
    "            tile_size=tile_size,\n",
    "            tile_overlap=tile_overlap,\n",
    "            use_fp16=use_fp16,\n",
    "            use_two_pass=USE_6X_UPSCALE\n",
    "        )\n",
    "        \n",
    "        results.append({\n",
    "            \"image_id\": config[\"image_id\"],\n",
    "            \"status\": \"Success\",\n",
    "            \"output\": output_path,\n",
    "            \"size\": f\"{config['width_inches']}x{config['height_inches']}\\\"\"\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Error: {e}\")\n",
    "        results.append({\n",
    "            \"image_id\": config[\"image_id\"],\n",
    "            \"status\": \"Failed\",\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "\n",
    "# Summary\n",
    "print(f\"\\n\\n{'='*60}\")\n",
    "print(\"BATCH COMPLETE - SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "success_count = sum(1 for r in results if r[\"status\"] == \"Success\")\n",
    "print(f\"\\nProcessed: {success_count}/{len(results)} images successfully\\n\")\n",
    "\n",
    "for r in results:\n",
    "    if r[\"status\"] == \"Success\":\n",
    "        print(f\"✅ {r['image_id'][:8]}... -> {r['size']} -> {Path(r['output']).name}\")\n",
    "    else:\n",
    "        print(f\"❌ {r['image_id'][:8]}... -> {r.get('error', 'Unknown error')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Image Processing (Optional)\n",
    "\n",
    "Use the cell below if you want to process a single image with custom settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Single Image Upscale (Optional)\n",
    "\n",
    "# Uncomment and modify to process a single image:\n",
    "\n",
    "# single_result = upscale_and_resize(\n",
    "#     image_path=\"input/your_image.jpg\",\n",
    "#     target_width=1650,   # 11 inches * 150 DPI\n",
    "#     target_height=2100,  # 14 inches * 150 DPI\n",
    "#     output_name=\"your_image_real-esrgan\",\n",
    "#     model_name=\"4x-UltraSharp.pth\",\n",
    "#     tile_size=512,\n",
    "#     tile_overlap=32,\n",
    "#     use_fp16=True\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
